{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avoid multiple loggin\n",
    "first_run = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate new embeddings files for a dataset\n",
      "Read file: HistoGlove.txt\n",
      "Added words: 6\n",
      ":: Transform tacMixed dataset ::\n",
      ":: Create Train Matrix ::\n",
      "Unknown-Tokens: 4.00%\n",
      ":: Create Dev Matrix ::\n",
      "Unknown-Tokens: 3.59%\n",
      ":: Create Test Matrix ::\n",
      "Unknown-Tokens: 1.33%\n",
      "DONE - Embeddings file saved: pkl/tacMixed_HistoGlove.pkl\n",
      "--- tacMixed ---\n",
      "2388 train sentences\n",
      "1919 dev sentences\n",
      "1985 test sentences\n",
      "LSTM-Size: [75, 75]\n",
      "_____________________________________________________________________________________________________________________________\n",
      "Layer (type)                             Output Shape               Param #        Connected to                              \n",
      "=============================================================================================================================\n",
      "words_input (InputLayer)                 (None, None)               0                                                        \n",
      "_____________________________________________________________________________________________________________________________\n",
      "lemma_input (InputLayer)                 (None, None)               0                                                        \n",
      "_____________________________________________________________________________________________________________________________\n",
      "casing_input (InputLayer)                (None, None)               0                                                        \n",
      "_____________________________________________________________________________________________________________________________\n",
      "POS_input (InputLayer)                   (None, None)               0                                                        \n",
      "_____________________________________________________________________________________________________________________________\n",
      "word_embeddings (Embedding)              (None, None, 300)          33334800       words_input[0][0]                         \n",
      "_____________________________________________________________________________________________________________________________\n",
      "lemma_emebddings (Embedding)             (None, None, 10)           124380         lemma_input[0][0]                         \n",
      "_____________________________________________________________________________________________________________________________\n",
      "casing_emebddings (Embedding)            (None, None, 10)           80             casing_input[0][0]                        \n",
      "_____________________________________________________________________________________________________________________________\n",
      "POS_emebddings (Embedding)               (None, None, 10)           460            POS_input[0][0]                           \n",
      "_____________________________________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)              (None, None, 330)          0              word_embeddings[0][0]                     \n",
      "                                                                                   lemma_emebddings[0][0]                    \n",
      "                                                                                   casing_emebddings[0][0]                   \n",
      "                                                                                   POS_emebddings[0][0]                      \n",
      "_____________________________________________________________________________________________________________________________\n",
      "shared_varLSTM_1 (Bidirectional)         (None, None, 150)          243600         concatenate_8[0][0]                       \n",
      "_____________________________________________________________________________________________________________________________\n",
      "shared_varLSTM_2 (Bidirectional)         (None, None, 150)          135600         shared_varLSTM_1[0][0]                    \n",
      "_____________________________________________________________________________________________________________________________\n",
      "tacMixed_softmax (TimeDistributed)       (None, None, 3)            453            shared_varLSTM_2[0][0]                    \n",
      "=============================================================================================================================\n",
      "Total params: 33,839,373\n",
      "Trainable params: 504,573\n",
      "Non-trainable params: 33,334,800\n",
      "_____________________________________________________________________________________________________________________________\n",
      "\n",
      "--------- Epoch 1 -----------\n",
      "12.24 sec for training (12.24 total)\n",
      "-- tacMixed --\n",
      "Train-Data: Prec: 0.851, Rec: 0.173, F1: 0.2882\n",
      "Dev-Data: Prec: 0.820, Rec: 0.150, F1: 0.2531\n",
      "Wrong BIO-Encoding 1/141 labels, 0.71%\n",
      "Wrong BIO-Encoding 1/141 labels, 0.71%\n",
      "Test-Data: Prec: 0.679, Rec: 0.014, F1: 0.0269\n",
      "\n",
      "Scores from last epoch:\n",
      "  Train-Score: 0.2882\n",
      "  Dev-Score: 0.2531\n",
      "\n",
      "7.43 sec for evaluation\n",
      "\n",
      "--------- Epoch 2 -----------\n",
      "4.76 sec for training (17.01 total)\n",
      "-- tacMixed --\n",
      "Train-Data: Prec: 0.750, Rec: 0.653, F1: 0.6982\n",
      "Dev-Data: Prec: 0.614, Rec: 0.585, F1: 0.5988\n",
      "Wrong BIO-Encoding 1/1238 labels, 0.08%\n",
      "Wrong BIO-Encoding 1/1238 labels, 0.08%\n",
      "Test-Data: Prec: 0.771, Rec: 0.138, F1: 0.2339\n",
      "\n",
      "Scores from last epoch:\n",
      "  Train-Score: 0.6982\n",
      "  Dev-Score: 0.5988\n",
      "\n",
      "3.04 sec for evaluation\n",
      "\n",
      "--------- Epoch 3 -----------\n",
      "4.80 sec for training (21.81 total)\n",
      "-- tacMixed --\n",
      "Train-Data: Prec: 0.825, Rec: 0.720, F1: 0.7688\n",
      "Dev-Data: Prec: 0.678, Rec: 0.620, F1: 0.6478\n",
      "Wrong BIO-Encoding 1/1005 labels, 0.10%\n",
      "Wrong BIO-Encoding 1/1005 labels, 0.10%\n",
      "Test-Data: Prec: 0.793, Rec: 0.115, F1: 0.2009\n",
      "\n",
      "Scores from last epoch:\n",
      "  Train-Score: 0.7688\n",
      "  Dev-Score: 0.6478\n",
      "\n",
      "3.03 sec for evaluation\n",
      "\n",
      "--------- Epoch 4 -----------\n",
      "4.73 sec for training (26.54 total)\n",
      "-- tacMixed --\n",
      "Train-Data: Prec: 0.813, Rec: 0.791, F1: 0.8018\n",
      "Dev-Data: Prec: 0.651, Rec: 0.675, F1: 0.6627\n",
      "Wrong BIO-Encoding 1/1282 labels, 0.08%\n",
      "Wrong BIO-Encoding 1/1282 labels, 0.08%\n",
      "Test-Data: Prec: 0.742, Rec: 0.137, F1: 0.2317\n",
      "\n",
      "Scores from last epoch:\n",
      "  Train-Score: 0.8018\n",
      "  Dev-Score: 0.6627\n",
      "\n",
      "3.54 sec for evaluation\n",
      "\n",
      "--------- Epoch 5 -----------\n",
      "4.79 sec for training (31.33 total)\n",
      "-- tacMixed --\n",
      "Train-Data: Prec: 0.833, Rec: 0.807, F1: 0.8198\n",
      "Dev-Data: Prec: 0.655, Rec: 0.669, F1: 0.6619\n",
      "Wrong BIO-Encoding 1/1261 labels, 0.08%\n",
      "Wrong BIO-Encoding 1/1261 labels, 0.08%\n",
      "Test-Data: Prec: 0.745, Rec: 0.136, F1: 0.2296\n",
      "\n",
      "Scores from last epoch:\n",
      "  Train-Score: 0.8198\n",
      "  Dev-Score: 0.6619\n",
      "\n",
      "2.93 sec for evaluation\n",
      "\n",
      "--------- Epoch 6 -----------\n",
      "4.74 sec for training (36.06 total)\n",
      "-- tacMixed --\n",
      "Wrong BIO-Encoding 1/3593 labels, 0.03%\n",
      "Wrong BIO-Encoding 1/3593 labels, 0.03%\n",
      "Train-Data: Prec: 0.835, Rec: 0.846, F1: 0.8401\n",
      "Dev-Data: Prec: 0.628, Rec: 0.703, F1: 0.6634\n",
      "Wrong BIO-Encoding 1/1558 labels, 0.06%\n",
      "Wrong BIO-Encoding 1/1558 labels, 0.06%\n",
      "Test-Data: Prec: 0.709, Rec: 0.160, F1: 0.2605\n",
      "\n",
      "Scores from last epoch:\n",
      "  Train-Score: 0.8401\n",
      "  Dev-Score: 0.6634\n",
      "\n",
      "3.06 sec for evaluation\n",
      "\n",
      "--------- Epoch 7 -----------\n",
      "4.76 sec for training (40.82 total)\n",
      "-- tacMixed --\n",
      "Wrong BIO-Encoding 1/3486 labels, 0.03%\n",
      "Wrong BIO-Encoding 1/3486 labels, 0.03%\n",
      "Train-Data: Prec: 0.858, Rec: 0.844, F1: 0.8509\n",
      "Dev-Data: Prec: 0.640, Rec: 0.692, F1: 0.6651\n",
      "Wrong BIO-Encoding 2/1493 labels, 0.13%\n",
      "Wrong BIO-Encoding 2/1493 labels, 0.13%\n",
      "Test-Data: Prec: 0.730, Rec: 0.157, F1: 0.2587\n",
      "\n",
      "Scores from last epoch:\n",
      "  Train-Score: 0.8509\n",
      "  Dev-Score: 0.6651\n",
      "\n",
      "3.04 sec for evaluation\n",
      "\n",
      "--------- Epoch 8 -----------\n",
      "4.72 sec for training (45.54 total)\n",
      "-- tacMixed --\n",
      "Wrong BIO-Encoding 1/3425 labels, 0.03%\n",
      "Wrong BIO-Encoding 1/3425 labels, 0.03%\n",
      "Train-Data: Prec: 0.880, Rec: 0.850, F1: 0.8647\n",
      "Wrong BIO-Encoding 3/1739 labels, 0.17%\n",
      "Wrong BIO-Encoding 3/1739 labels, 0.17%\n",
      "Dev-Data: Prec: 0.652, Rec: 0.689, F1: 0.6698\n",
      "Wrong BIO-Encoding 5/1452 labels, 0.34%\n",
      "Wrong BIO-Encoding 5/1452 labels, 0.34%\n",
      "Test-Data: Prec: 0.715, Rec: 0.149, F1: 0.2472\n",
      "\n",
      "Scores from last epoch:\n",
      "  Train-Score: 0.8647\n",
      "  Dev-Score: 0.6698\n",
      "\n",
      "3.04 sec for evaluation\n",
      "\n",
      "--------- Epoch 9 -----------\n",
      "4.74 sec for training (50.28 total)\n",
      "-- tacMixed --\n",
      "Wrong BIO-Encoding 3/3734 labels, 0.08%\n",
      "Wrong BIO-Encoding 3/3734 labels, 0.08%\n",
      "Train-Data: Prec: 0.863, Rec: 0.908, F1: 0.8848\n",
      "Wrong BIO-Encoding 1/2019 labels, 0.05%\n",
      "Wrong BIO-Encoding 1/2019 labels, 0.05%\n",
      "Dev-Data: Prec: 0.591, Rec: 0.726, F1: 0.6516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong BIO-Encoding 8/1787 labels, 0.45%\n",
      "Wrong BIO-Encoding 8/1787 labels, 0.45%\n",
      "Test-Data: Prec: 0.693, Rec: 0.178, F1: 0.2835\n",
      "\n",
      "Scores from last epoch:\n",
      "  Train-Score: 0.8848\n",
      "  Dev-Score: 0.6516\n",
      "\n",
      "2.94 sec for evaluation\n",
      "\n",
      "--------- Epoch 10 -----------\n",
      "4.75 sec for training (55.03 total)\n",
      "-- tacMixed --\n",
      "Wrong BIO-Encoding 1/3662 labels, 0.03%\n",
      "Wrong BIO-Encoding 1/3662 labels, 0.03%\n",
      "Train-Data: Prec: 0.888, Rec: 0.917, F1: 0.9026\n",
      "Wrong BIO-Encoding 1/2084 labels, 0.05%\n",
      "Wrong BIO-Encoding 1/2084 labels, 0.05%\n",
      "Dev-Data: Prec: 0.570, Rec: 0.723, F1: 0.6375\n",
      "Wrong BIO-Encoding 6/1958 labels, 0.31%\n",
      "Wrong BIO-Encoding 6/1958 labels, 0.31%\n",
      "Test-Data: Prec: 0.679, Rec: 0.192, F1: 0.2990\n",
      "\n",
      "Scores from last epoch:\n",
      "  Train-Score: 0.9026\n",
      "  Dev-Score: 0.6375\n",
      "\n",
      "2.91 sec for evaluation\n",
      "\n",
      "--------- Epoch 11 -----------\n",
      "4.76 sec for training (59.79 total)\n",
      "-- tacMixed --\n",
      "Wrong BIO-Encoding 4/3688 labels, 0.11%\n",
      "Wrong BIO-Encoding 4/3688 labels, 0.11%\n",
      "Train-Data: Prec: 0.895, Rec: 0.930, F1: 0.9119\n",
      "Wrong BIO-Encoding 1/2093 labels, 0.05%\n",
      "Wrong BIO-Encoding 1/2093 labels, 0.05%\n",
      "Dev-Data: Prec: 0.576, Rec: 0.732, F1: 0.6445\n",
      "Wrong BIO-Encoding 6/1986 labels, 0.30%\n",
      "Wrong BIO-Encoding 6/1986 labels, 0.30%\n",
      "Test-Data: Prec: 0.671, Rec: 0.192, F1: 0.2985\n",
      "\n",
      "Scores from last epoch:\n",
      "  Train-Score: 0.9119\n",
      "  Dev-Score: 0.6445\n",
      "\n",
      "2.95 sec for evaluation\n",
      "\n",
      "--------- Epoch 12 -----------\n",
      "4.71 sec for training (64.50 total)\n",
      "-- tacMixed --\n",
      "Wrong BIO-Encoding 4/3493 labels, 0.11%\n",
      "Wrong BIO-Encoding 4/3493 labels, 0.11%\n",
      "Train-Data: Prec: 0.940, Rec: 0.925, F1: 0.9323\n",
      "Wrong BIO-Encoding 7/1852 labels, 0.38%\n",
      "Wrong BIO-Encoding 7/1852 labels, 0.38%\n",
      "Dev-Data: Prec: 0.621, Rec: 0.696, F1: 0.6563\n",
      "Wrong BIO-Encoding 14/1710 labels, 0.82%\n",
      "Wrong BIO-Encoding 14/1710 labels, 0.82%\n",
      "Test-Data: Prec: 0.695, Rec: 0.170, F1: 0.2737\n",
      "\n",
      "Scores from last epoch:\n",
      "  Train-Score: 0.9323\n",
      "  Dev-Score: 0.6563\n",
      "\n",
      "2.92 sec for evaluation\n",
      "\n",
      "--------- Epoch 13 -----------\n",
      "4.73 sec for training (69.23 total)\n",
      "-- tacMixed --\n",
      "Wrong BIO-Encoding 1/3616 labels, 0.03%\n",
      "Wrong BIO-Encoding 1/3616 labels, 0.03%\n",
      "Train-Data: Prec: 0.936, Rec: 0.954, F1: 0.9450\n",
      "Wrong BIO-Encoding 6/2021 labels, 0.30%\n",
      "Wrong BIO-Encoding 5/2020 labels, 0.25%\n",
      "Dev-Data: Prec: 0.582, Rec: 0.715, F1: 0.6414\n",
      "Wrong BIO-Encoding 28/1968 labels, 1.42%\n",
      "Wrong BIO-Encoding 27/1967 labels, 1.37%\n",
      "Test-Data: Prec: 0.696, Rec: 0.195, F1: 0.3048\n",
      "\n",
      "Scores from last epoch:\n",
      "  Train-Score: 0.9450\n",
      "  Dev-Score: 0.6414\n",
      "\n",
      "2.90 sec for evaluation\n",
      "\n",
      "--------- Epoch 14 -----------\n",
      "4.76 sec for training (73.99 total)\n",
      "-- tacMixed --\n",
      "Wrong BIO-Encoding 16/3804 labels, 0.42%\n",
      "Wrong BIO-Encoding 13/3801 labels, 0.34%\n",
      "Train-Data: Prec: 0.908, Rec: 0.971, F1: 0.9385\n",
      "Wrong BIO-Encoding 11/2309 labels, 0.48%\n",
      "Wrong BIO-Encoding 10/2308 labels, 0.43%\n",
      "Dev-Data: Prec: 0.534, Rec: 0.746, F1: 0.6220\n",
      "Wrong BIO-Encoding 44/2332 labels, 1.89%\n",
      "Wrong BIO-Encoding 41/2329 labels, 1.76%\n",
      "Test-Data: Prec: 0.673, Rec: 0.223, F1: 0.3345\n",
      "\n",
      "Scores from last epoch:\n",
      "  Train-Score: 0.9385\n",
      "  Dev-Score: 0.6220\n",
      "\n",
      "2.89 sec for evaluation\n",
      "\n",
      "--------- Epoch 15 -----------\n",
      "4.85 sec for training (78.84 total)\n",
      "-- tacMixed --\n",
      "Train-Data: Prec: 0.972, Rec: 0.949, F1: 0.9605\n",
      "Wrong BIO-Encoding 4/1854 labels, 0.22%\n",
      "Wrong BIO-Encoding 4/1854 labels, 0.22%\n",
      "Dev-Data: Prec: 0.601, Rec: 0.676, F1: 0.6365\n",
      "Wrong BIO-Encoding 14/1714 labels, 0.82%\n",
      "Wrong BIO-Encoding 14/1714 labels, 0.82%\n",
      "Test-Data: Prec: 0.708, Rec: 0.174, F1: 0.2794\n",
      "\n",
      "Scores from last epoch:\n",
      "  Train-Score: 0.9605\n",
      "  Dev-Score: 0.6365\n",
      "\n",
      "2.93 sec for evaluation\n",
      "\n",
      "--------- Epoch 16 -----------\n",
      "4.75 sec for training (83.58 total)\n",
      "-- tacMixed --\n",
      "Wrong BIO-Encoding 1/3640 labels, 0.03%\n",
      "Wrong BIO-Encoding 1/3640 labels, 0.03%\n",
      "Train-Data: Prec: 0.951, Rec: 0.977, F1: 0.9638\n",
      "Wrong BIO-Encoding 5/2055 labels, 0.24%\n",
      "Wrong BIO-Encoding 5/2055 labels, 0.24%\n",
      "Dev-Data: Prec: 0.565, Rec: 0.704, F1: 0.6270\n",
      "Wrong BIO-Encoding 17/2071 labels, 0.82%\n",
      "Wrong BIO-Encoding 16/2070 labels, 0.77%\n",
      "Test-Data: Prec: 0.697, Rec: 0.209, F1: 0.3211\n",
      "\n",
      "Scores from last epoch:\n",
      "  Train-Score: 0.9638\n",
      "  Dev-Score: 0.6270\n",
      "\n",
      "2.90 sec for evaluation\n",
      "\n",
      "--------- Epoch 17 -----------\n",
      "4.72 sec for training (88.30 total)\n",
      "-- tacMixed --\n",
      "Wrong BIO-Encoding 5/3669 labels, 0.14%\n",
      "Wrong BIO-Encoding 4/3668 labels, 0.11%\n",
      "Train-Data: Prec: 0.954, Rec: 0.987, F1: 0.9699\n",
      "Wrong BIO-Encoding 8/2246 labels, 0.36%\n",
      "Wrong BIO-Encoding 7/2245 labels, 0.31%\n",
      "Dev-Data: Prec: 0.539, Rec: 0.734, F1: 0.6218\n",
      "Wrong BIO-Encoding 25/2349 labels, 1.06%\n",
      "Wrong BIO-Encoding 24/2348 labels, 1.02%\n",
      "Test-Data: Prec: 0.657, Rec: 0.223, F1: 0.3330\n",
      "\n",
      "Scores from last epoch:\n",
      "  Train-Score: 0.9699\n",
      "  Dev-Score: 0.6218\n",
      "\n",
      "2.93 sec for evaluation\n",
      "\n",
      "--------- Epoch 18 -----------\n",
      "4.73 sec for training (93.03 total)\n",
      "-- tacMixed --\n",
      "Train-Data: Prec: 0.968, Rec: 0.985, F1: 0.9762\n",
      "Dev-Data: Prec: 0.558, Rec: 0.714, F1: 0.6263\n",
      "Wrong BIO-Encoding 9/2067 labels, 0.44%\n",
      "Wrong BIO-Encoding 9/2067 labels, 0.44%\n",
      "Test-Data: Prec: 0.693, Rec: 0.206, F1: 0.3177\n",
      "\n",
      "Scores from last epoch:\n",
      "  Train-Score: 0.9762\n",
      "  Dev-Score: 0.6263\n",
      "\n",
      "2.92 sec for evaluation\n",
      "\n",
      "Scores from epoch with best dev-scores:\n",
      "  Test-Score: 0.2472\n",
      "  Dev-Score: 0.6698\n",
      "!!! Early stopping, no improvement after 10 epochs !!!\n"
     ]
    }
   ],
   "source": [
    "# This script trains the BiLSTM-CRF architecture for part-of-speech tagging using\n",
    "# the universal dependency dataset (http://universaldependencies.org/).\n",
    "# The code use the embeddings by Komninos et al. (https://www.cs.york.ac.uk/nlp/extvec/)\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "from neuralnets.BiLSTM import BiLSTM\n",
    "from util.preprocessing import perpareDataset, loadDatasetPickle\n",
    "\n",
    "'''\n",
    "# :: Change into the working dir of the script ::\n",
    "abspath = os.path.abspath(__file__)\n",
    "dname = os.path.dirname(abspath)\n",
    "os.chdir(dname)\n",
    "'''\n",
    "\n",
    "if first_run:\n",
    "    first_run = False\n",
    "    # :: Logging level ::\n",
    "    loggingLevel = logging.INFO\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(loggingLevel)\n",
    "\n",
    "    ch = logging.StreamHandler(sys.stdout)\n",
    "    ch.setLevel(loggingLevel)\n",
    "    formatter = logging.Formatter('%(message)s')\n",
    "    ch.setFormatter(formatter)\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "\n",
    "######################################################\n",
    "#\n",
    "# Data preprocessing\n",
    "#\n",
    "######################################################\n",
    "datasets = {\n",
    "    'tacMixed':                                   #Name of the dataset\n",
    "        {'columns': {0:'tokens', 1:'lemma', 2:'POS', 5:'chunk_BIO'},\n",
    "         'label': 'chunk_BIO',                                #Which column we like to predict\n",
    "         'evaluate': True,                                  #Should we evaluate on this task? Set true always for single task setups\n",
    "         'commentSymbol': None} \n",
    "}\n",
    "\n",
    "\n",
    "#Path on your computer to the word embeddings\n",
    "#embeddingsPath = 'glove.6B.300d.txt'\n",
    "embeddingsPath = 'HistoGlove.txt'\n",
    "\n",
    "\n",
    "#Prepares the dataset to be used with the LSTM-network. Creates and stores cPickle files in the pkl/ folder ::\n",
    "pickleFile = perpareDataset(embeddingsPath, datasets)\n",
    "\n",
    "\n",
    "######################################################\n",
    "#\n",
    "# The training of the network starts here\n",
    "#\n",
    "######################################################\n",
    "\n",
    "\n",
    "#Load the embeddings and the dataset\n",
    "embeddings, mappings, data = loadDatasetPickle(pickleFile)\n",
    "\n",
    "# Some network hyperparameters\n",
    "params = {'classifier': ['Softmax'], 'LSTM-Size': [75, 75], 'dropout': (0.25, 0.25),\n",
    "         'featureNames': ['tokens', 'lemma', 'casing', 'POS'], 'addFeatureDimensions': 10,\n",
    "         'miniBatchSize': 32, 'earlyStopping': 10}\n",
    "\n",
    "model = BiLSTM(params)\n",
    "model.setMappings(mappings, embeddings)\n",
    "model.setDataset(datasets, data)\n",
    "model.storeResults('./tacMixedHistoGlove.csv') #Path to store performance scores for dev / test\n",
    "model.modelSavePath = \"models/[ModelName]_[DevScore]_[TestScore]_[Epoch].h5\" #Path to store models\n",
    "model.fit(epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inforet",
   "language": "python",
   "name": "inforet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
